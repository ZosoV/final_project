digraph {
	graph [size="31.049999999999997,31.049999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140157419866352 [label="
 ()" fillcolor=darkolivegreen1]
	140157419958384 [label="AddBackward0
------------
alpha: 1"]
	140157419946576 -> 140157419958384
	140157419946576 -> 140157419864432 [dir=none]
	140157419864432 [label="other
 ()" fillcolor=orange]
	140157419946576 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419955552 -> 140157419946576
	140157419955552 [label="MeanBackward0
----------------------
self_sym_numel:    128
self_sym_sizes: (128,)"]
	140157419959872 -> 140157419955552
	140157419959872 -> 140157420040944 [dir=none]
	140157420040944 [label="self
 (128)" fillcolor=orange]
	140157419959872 -> 140157420035952 [dir=none]
	140157420035952 [label="target
 (128)" fillcolor=orange]
	140157419959872 [label="MseLossBackward0
-------------------------
reduction:              0
self     : [saved tensor]
target   : [saved tensor]"]
	140157419950560 -> 140157419959872
	140157419950560 [label="SumBackward1
---------------------------------------
dim           : (18446744073709551615,)
keepdim       :                   False
self_sym_sizes:                (128, 2)"]
	140157419948784 -> 140157419950560
	140157419948784 -> 140157420029328 [dir=none]
	140157420029328 [label="other
 (128, 2)" fillcolor=orange]
	140157419948784 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419949456 -> 140157419948784
	140157419949456 -> 140157420035568 [dir=none]
	140157420035568 [label="mat1
 (128, 84)" fillcolor=orange]
	140157419949456 -> 140157419865488 [dir=none]
	140157419865488 [label="mat2
 (84, 2)" fillcolor=orange]
	140157419949456 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (128, 84)
mat1_sym_strides:        (84, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (84, 2)
mat2_sym_strides:        (1, 84)"]
	140157419954928 -> 140157419949456
	140157428126288 [label="module.0.module.mlp_layers.1.bias
 (2)" fillcolor=lightblue]
	140157428126288 -> 140157419954928
	140157419954928 [label=AccumulateGrad]
	140157419958624 -> 140157419949456
	140157419958624 -> 140157419879216 [dir=none]
	140157419879216 [label="result
 (128, 84)" fillcolor=orange]
	140157419958624 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140157419956752 -> 140157419958624
	140157419956752 -> 140157420030000 [dir=none]
	140157420030000 [label="mat1
 (128, 3)" fillcolor=orange]
	140157419956752 -> 140157419866736 [dir=none]
	140157419866736 [label="mat2
 (3, 84)" fillcolor=orange]
	140157419956752 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (128, 3)
mat1_sym_strides:         (3, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (3, 84)
mat2_sym_strides:         (1, 3)"]
	140157419952336 -> 140157419956752
	140157427726672 [label="module.0.module.mlp_layers.0.bias
 (84)" fillcolor=lightblue]
	140157427726672 -> 140157419952336
	140157419952336 [label=AccumulateGrad]
	140157419947680 -> 140157419956752
	140157419947680 -> 140157419865008 [dir=none]
	140157419865008 [label="result
 (128, 3)" fillcolor=orange]
	140157419947680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140157419947632 -> 140157419947680
	140157419947632 -> 140157428133968 [dir=none]
	140157428133968 [label="mat1
 (128, 84)" fillcolor=orange]
	140157419947632 -> 140157419874992 [dir=none]
	140157419874992 [label="mat2
 (84, 3)" fillcolor=orange]
	140157419947632 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (128, 84)
mat1_sym_strides:        (84, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (84, 3)
mat2_sym_strides:        (1, 84)"]
	140157419947824 -> 140157419947632
	140157427727920 [label="module.0.module.layers.2.bias
 (3)" fillcolor=lightblue]
	140157427727920 -> 140157419947824
	140157419947824 [label=AccumulateGrad]
	140157419950944 -> 140157419947632
	140157419950944 -> 140157419870960 [dir=none]
	140157419870960 [label="result
 (128, 84)" fillcolor=orange]
	140157419950944 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140157419960064 -> 140157419950944
	140157419960064 -> 140157424222672 [dir=none]
	140157424222672 [label="mat1
 (128, 120)" fillcolor=orange]
	140157419960064 -> 140157419879888 [dir=none]
	140157419879888 [label="mat2
 (120, 84)" fillcolor=orange]
	140157419960064 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :     (128, 120)
mat1_sym_strides:       (120, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :      (120, 84)
mat2_sym_strides:       (1, 120)"]
	140157424000720 -> 140157419960064
	140157427727728 [label="module.0.module.layers.1.bias
 (84)" fillcolor=lightblue]
	140157427727728 -> 140157424000720
	140157424000720 [label=AccumulateGrad]
	140157419957472 -> 140157419960064
	140157419957472 -> 140157419871728 [dir=none]
	140157419871728 [label="result
 (128, 120)" fillcolor=orange]
	140157419957472 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	140157419953776 -> 140157419957472
	140157419953776 -> 140157419962448 [dir=none]
	140157419962448 [label="mat1
 (128, 4)" fillcolor=orange]
	140157419953776 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :       (128, 4)
mat1_sym_strides:             ()
mat2            :           None
mat2_sym_sizes  :       (4, 120)
mat2_sym_strides:         (1, 4)"]
	140157419993360 -> 140157419953776
	140157427726192 [label="module.0.module.layers.0.bias
 (120)" fillcolor=lightblue]
	140157427726192 -> 140157419993360
	140157419993360 [label=AccumulateGrad]
	140157419950848 -> 140157419953776
	140157419950848 [label=TBackward0]
	140157419993072 -> 140157419950848
	140157427728208 [label="module.0.module.layers.0.weight
 (120, 4)" fillcolor=lightblue]
	140157427728208 -> 140157419993072
	140157419993072 [label=AccumulateGrad]
	140157419954688 -> 140157419960064
	140157419954688 [label=TBackward0]
	140157419994992 -> 140157419954688
	140157427728304 [label="module.0.module.layers.1.weight
 (84, 120)" fillcolor=lightblue]
	140157427728304 -> 140157419994992
	140157419994992 [label=AccumulateGrad]
	140157419955264 -> 140157419947632
	140157419955264 [label=TBackward0]
	140157424000144 -> 140157419955264
	140157427727824 [label="module.0.module.layers.2.weight
 (3, 84)" fillcolor=lightblue]
	140157427727824 -> 140157424000144
	140157424000144 [label=AccumulateGrad]
	140157419956512 -> 140157419956752
	140157419956512 [label=TBackward0]
	140157419957280 -> 140157419956512
	140157427725904 [label="module.0.module.mlp_layers.0.weight
 (84, 3)" fillcolor=lightblue]
	140157427725904 -> 140157419957280
	140157419957280 [label=AccumulateGrad]
	140157419949120 -> 140157419949456
	140157419949120 [label=TBackward0]
	140157419957856 -> 140157419949120
	140157428126384 [label="module.0.module.mlp_layers.1.weight
 (2, 84)" fillcolor=lightblue]
	140157428126384 -> 140157419957856
	140157419957856 [label=AccumulateGrad]
	140157419961936 -> 140157419958384
	140157419961936 -> 140157423681360 [dir=none]
	140157423681360 [label="other
 ()" fillcolor=orange]
	140157419961936 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419949504 -> 140157419961936
	140157419949504 [label="MeanBackward0
------------------
self_sym_numel:  1
self_sym_sizes: ()"]
	140157419946816 -> 140157419949504
	140157419946816 -> 140157419872496 [dir=none]
	140157419872496 [label="self
 (4096)" fillcolor=orange]
	140157419946816 -> 140157467450384 [dir=none]
	140157467450384 [label="target
 (4096)" fillcolor=orange]
	140157419946816 [label="HuberLossBackward0
-------------------------
delta    :            1.0
reduction:              1
self     : [saved tensor]
target   : [saved tensor]"]
	140157419960496 -> 140157419946816
	140157419960496 [label="AddBackward0
------------
alpha: 1"]
	140157419949648 -> 140157419960496
	140157419949648 -> 140157423667728 [dir=none]
	140157423667728 [label="other
 ()" fillcolor=orange]
	140157419949648 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419955792 -> 140157419949648
	140157419955792 [label="AddBackward0
------------
alpha: 1"]
	140157419946240 -> 140157419955792
	140157419946240 [label="SumBackward1
---------------------------------------
dim           : (18446744073709551615,)
keepdim       :                   False
self_sym_sizes:               (4096, 3)"]
	140157419953440 -> 140157419946240
	140157419953440 -> 140157467449520 [dir=none]
	140157467449520 [label="self
 (4096, 3)" fillcolor=orange]
	140157419953440 [label="PowBackward0
------------------------
exponent:              2
self    : [saved tensor]"]
	140157419958864 -> 140157419953440
	140157419958864 [label="ViewBackward0
---------------------------
self_sym_sizes: (64, 64, 3)"]
	140157419957136 -> 140157419958864
	140157419957136 [label="ViewBackward0
-------------------------
self_sym_sizes: (64, 192)"]
	140157419953824 -> 140157419957136
	140157419953824 [label="RepeatBackward0
-----------------------
repeats       : (1, 64)
self_sym_sizes: (64, 3)"]
	140157423876320 -> 140157419953824
	140157423876320 [label="SliceBackward0
-----------------------------------
dim           :                   0
end           : 9223372036854775807
self_sym_sizes:            (128, 3)
start         :                   0
step          :                   2"]
	140157419947680 -> 140157423876320
	140157419949600 -> 140157419960496
	140157419949600 -> 140157420053200 [dir=none]
	140157420053200 [label="other
 ()" fillcolor=orange]
	140157419949600 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419959776 -> 140157419949600
	140157419959776 -> 140157420047536 [dir=none]
	140157420047536 [label="other
 (4096)" fillcolor=orange]
	140157419959776 -> 140157420054736 [dir=none]
	140157420054736 [label="self
 (4096)" fillcolor=orange]
	140157419959776 [label="Atan2Backward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140157419949360 -> 140157419959776
	140157419949360 -> 140157420060496 [dir=none]
	140157420060496 [label="result
 (4096)" fillcolor=orange]
	140157419949360 [label="SqrtBackward0
----------------------
result: [saved tensor]"]
	140157419948208 -> 140157419949360
	140157419948208 -> 140157420048112 [dir=none]
	140157420048112 [label="other
 (4096)" fillcolor=orange]
	140157419948208 -> 140157420048304 [dir=none]
	140157420048304 [label="self
 (4096)" fillcolor=orange]
	140157419948208 [label="MaximumBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140157427964352 -> 140157419948208
	140157427964352 [label="RsubBackward1
-------------
alpha: 1"]
	140157451048736 -> 140157427964352
	140157451048736 -> 140157420047536 [dir=none]
	140157420047536 [label="self
 (4096)" fillcolor=orange]
	140157451048736 [label="PowBackward0
------------------------
exponent:              2
self    : [saved tensor]"]
	140157419958336 -> 140157451048736
	140157419958336 -> 140157420048592 [dir=none]
	140157420048592 [label="other
 (4096)" fillcolor=orange]
	140157419958336 -> 140157420059728 [dir=none]
	140157420059728 [label="self
 (4096)" fillcolor=orange]
	140157419958336 [label="DivBackward0
---------------------
other: [saved tensor]
self : [saved tensor]"]
	140157419986688 -> 140157419958336
	140157419986688 [label="SumBackward1
-------------------------
dim           :      (1,)
keepdim       :     False
self_sym_sizes: (4096, 3)"]
	140157419983088 -> 140157419986688
	140157419983088 -> 140157467451248 [dir=none]
	140157467451248 [label="other
 (4096, 3)" fillcolor=orange]
	140157419983088 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419958864 -> 140157419983088
	140157419989664 -> 140157419958336
	140157419989664 [label="AddBackward0
------------
alpha: 1"]
	140157419989520 -> 140157419989664
	140157419989520 -> 140157420051952 [dir=none]
	140157420051952 [label="other
 (4096)" fillcolor=orange]
	140157419989520 [label="MulBackward0
---------------------
other: [saved tensor]
self :           None"]
	140157419985536 -> 140157419989520
	140157419985536 -> 140157420048880 [dir=none]
	140157420048880 [label="result
 (4096)" fillcolor=orange]
	140157419985536 [label="SqrtBackward0
----------------------
result: [saved tensor]"]
	140157419993648 -> 140157419985536
	140157419993648 [label="SumBackward1
-------------------------
dim           :      (1,)
keepdim       :     False
self_sym_sizes: (4096, 3)"]
	140157419982224 -> 140157419993648
	140157419982224 -> 140157467449520 [dir=none]
	140157467449520 [label="self
 (4096, 3)" fillcolor=orange]
	140157419982224 [label="PowBackward0
------------------------
exponent:              2
self    : [saved tensor]"]
	140157419958864 -> 140157419982224
	140157419958336 -> 140157419959776
	140157419958384 -> 140157419866352
}
