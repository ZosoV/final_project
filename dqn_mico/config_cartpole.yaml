  
device: null

exp_name: DQN

# Environment
# SEEDS: [118398, 676190, 786456, 171936, 887739, 919409, 711872, 442081, 189061, 117840]
env:
  env_name: CartPole-v1
  seed: 118398

# collector
collector:
  total_frames: 210_100
  frames_per_batch: 10
  eps_start: 1.0
  eps_end: 0.05
  annealing_frames: 150_000
  init_random_frames: 300

# policy
policy:
  type: "MLP_encoder"  # Example type, adjust based on your architecture (e.g., CNN, RNN)
  encoder:
    layers: [120, 84]
    out_features: 2
  q_net:
    layers: [84, 48] # [10] # TODO: check this configuration and the LR
  activation: "ReLU"  # Activation function used in the layers

# buffer
buffer:
  buffer_size: 10_000 # Check the paper and the effect of the buffer size to have an intuition
  batch_size: 128
  prioritized_replay: True
  alpha: 0.7
  beta: 0.4
  priority_type: "all_vs_all" # "all_vs_all" or "current_vs_next"
  priority_alpha: 0

# logger
logger:
  backend: wandb
  project_name: torchrl_example_dqn
  group_name: null
  test_interval: 25_000
  num_test_episodes: 5
  video: False

# Optim
optim:
  lr: 0.000002 #2.5e-4
  max_grad_norm: 10

# loss
loss:
  gamma: 0.99
  hard_update_freq: 50
  num_updates: 1
  mico_weight: 0.01 #0.5
  mico_beta: 0.1
  mico_gamma: 0.99
