{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import ExplorationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fce9e3300b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
    "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq\n",
    "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
    "from torch.optim import Adam\n",
    "from torchrl.objectives import DQNLoss, SoftUpdate\n",
    "from torchrl._utils import logger as torchrl_logger\n",
    "from torchrl.record import CSVLogger, VideoRecorder\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosov/anaconda3/envs/final-project/lib/python3.11/site-packages/torchrl/envs/common.py:2989: DeprecationWarning: Your wrapper was not given a device. Currently, this value will default to 'cpu'. From v0.5 it will default to `None`. With a device of None, no device casting is performed and the resulting tensordicts are deviceless. Please set your device accordingly.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "795726461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the environment\n",
    "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
    "env.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotDiscreteTensorSpec(\n",
       "    shape=torch.Size([2]),\n",
       "    space=DiscreteBox(n=2),\n",
       "    device=cpu,\n",
       "    dtype=torch.int64,\n",
       "    domain=discrete)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscreteBox(n=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.specs[\"input_spec\", \"full_action_spec\", \"action\"].space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = env.observation_spec[\"observation\"].shape\n",
    "env_specs = env.specs\n",
    "num_outputs = env_specs[\"input_spec\", \"full_action_spec\", \"action\"].space.n\n",
    "action_spec = env_specs[\"input_spec\", \"full_action_spec\", \"action\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosov/anaconda3/envs/final-project/lib/python3.11/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# Define the network for DQN values\n",
    "value_mlp = MLP(out_features=env.action_spec.shape[-1], \n",
    "                num_cells=[64, 64])\n",
    "value_net = Mod(value_mlp, \n",
    "                in_keys=[\"observation\"], \n",
    "                out_keys=[\"action_value\"])\n",
    "\n",
    "# Define the policy. QValueModule adds the argmax step to the Q-values\n",
    "policy = Seq(value_net, \n",
    "             QValueModule(spec=env.action_spec))\n",
    "\n",
    "# Define the exploration step (e-greedy policy)\n",
    "exploration_module = EGreedyModule(\n",
    "    env.action_spec, \n",
    "    annealing_num_steps=100_000, \n",
    "    eps_init=0.5\n",
    ")\n",
    "policy_explore = Seq(policy, \n",
    "                     exploration_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to collect the data (experiences)\n",
    "init_rand_steps = 5000 # warm-up steps\n",
    "frames_per_batch = 10\n",
    "optim_steps = 10\n",
    "replay_capacity = 100_000\n",
    "\n",
    "# NOTE: collector will gather rollouts continously\n",
    "# If the current trajectory ends, it will start a new one\n",
    "# NOTE: the rollout gotten from the collector is a dictionary\n",
    "# that defines the sate and next state as a tensor with a batch dimension in the begining\n",
    "# for example a rollout of 10 steps will have a tensor of observation of 10 in the batch dimension\n",
    "# and the next will also have 10 which are all the tensors of the next state\n",
    "# Practically, next is as you will shift the tensor of observation by one step\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=500_100,\n",
    "    init_random_frames=init_rand_steps,\n",
    ")\n",
    "rb = ReplayBuffer(storage=LazyTensorStorage(replay_capacity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = DQNLoss(value_network=policy, \n",
    "               action_space=env.action_spec, \n",
    "               delay_value=True) # delay_value=True means we will use a target network\n",
    "optim = Adam(loss.parameters(), lr=0.02)\n",
    "\n",
    "# eps: will be used to update the target network as \n",
    "# \\theta_t = \\theta_{t-1} * \\epsilon + \\theta_t * (1-\\epsilon)\n",
    "# where eps = 1 is hard update\n",
    "updater = SoftUpdate(loss, eps=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosov/anaconda3/envs/final-project/lib/python3.11/site-packages/torchrl/envs/common.py:2989: DeprecationWarning: Your wrapper was not given a device. Currently, this value will default to 'cpu'. From v0.5 it will default to `None`. With a device of None, no device casting is performed and the resulting tensordicts are deviceless. Please set your device accordingly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the recording and logging\n",
    "path = \"./training_loop\"\n",
    "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
    "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
    "record_env = TransformedEnv(\n",
    "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first -1 0\n",
      "second 10 10\n",
      "first 0 0\n",
      "second 20 20\n",
      "first 0 0\n",
      "second 30 0\n",
      "first 0 1\n",
      "second 40 10\n",
      "first 1 1\n",
      "second 50 20\n",
      "first 1 1\n",
      "second 60 0\n",
      "first 1 2\n",
      "second 70 10\n",
      "first 2 2\n",
      "second 80 20\n",
      "first 2 2\n",
      "second 90 0\n",
      "first 2 3\n",
      "second 100 10\n",
      "first 3 3\n",
      "second 110 20\n",
      "first 3 3\n",
      "second 120 0\n",
      "first 3 4\n",
      "second 130 10\n",
      "first 4 4\n",
      "second 140 20\n",
      "first 4 4\n",
      "second 150 0\n",
      "first 4 5\n",
      "second 160 10\n",
      "first 5 5\n",
      "second 170 20\n",
      "first 5 5\n",
      "second 180 0\n",
      "first 5 6\n",
      "second 190 10\n",
      "first 6 6\n",
      "second 200 20\n",
      "first 6 6\n",
      "second 210 0\n",
      "first 6 7\n",
      "second 220 10\n",
      "first 7 7\n",
      "second 230 20\n",
      "first 7 7\n",
      "second 240 0\n",
      "first 7 8\n",
      "second 250 10\n",
      "first 8 8\n",
      "second 260 20\n",
      "first 8 8\n",
      "second 270 0\n",
      "first 8 9\n",
      "second 280 10\n",
      "first 9 9\n",
      "second 290 20\n",
      "first 9 9\n",
      "second 300 0\n",
      "first 9 10\n",
      "second 310 10\n",
      "first 10 10\n",
      "second 320 20\n",
      "first 10 10\n",
      "second 330 0\n",
      "first 10 11\n",
      "second 340 10\n",
      "first 11 11\n",
      "second 350 20\n",
      "first 11 11\n",
      "second 360 0\n",
      "first 11 12\n",
      "second 370 10\n",
      "first 12 12\n",
      "second 380 20\n",
      "first 12 12\n",
      "second 390 0\n",
      "first 12 13\n",
      "second 400 10\n",
      "first 13 13\n",
      "second 410 20\n",
      "first 13 13\n",
      "second 420 0\n",
      "first 13 14\n",
      "second 430 10\n",
      "first 14 14\n",
      "second 440 20\n",
      "first 14 14\n",
      "second 450 0\n",
      "first 14 15\n",
      "second 460 10\n",
      "first 15 15\n",
      "second 470 20\n",
      "first 15 15\n",
      "second 480 0\n",
      "first 15 16\n",
      "second 490 10\n",
      "first 16 16\n",
      "second 500 20\n",
      "first 16 16\n",
      "second 510 0\n",
      "first 16 17\n",
      "second 520 10\n",
      "first 17 17\n",
      "second 530 20\n",
      "first 17 17\n",
      "second 540 0\n",
      "first 17 18\n",
      "second 550 10\n",
      "first 18 18\n",
      "second 560 20\n",
      "first 18 18\n",
      "second 570 0\n",
      "first 18 19\n",
      "second 580 10\n",
      "first 19 19\n",
      "second 590 20\n",
      "first 19 19\n",
      "second 600 0\n",
      "first 19 20\n",
      "second 610 10\n",
      "first 20 20\n",
      "second 620 20\n",
      "first 20 20\n",
      "second 630 0\n",
      "first 20 21\n",
      "second 640 10\n",
      "first 21 21\n",
      "second 650 20\n",
      "first 21 21\n",
      "second 660 0\n",
      "first 21 22\n",
      "second 670 10\n",
      "first 22 22\n",
      "second 680 20\n",
      "first 22 22\n",
      "second 690 0\n",
      "first 22 23\n",
      "second 700 10\n",
      "first 23 23\n",
      "second 710 20\n",
      "first 23 23\n",
      "second 720 0\n",
      "first 23 24\n",
      "second 730 10\n",
      "first 24 24\n",
      "second 740 20\n",
      "first 24 24\n",
      "second 750 0\n",
      "first 24 25\n",
      "second 760 10\n",
      "first 25 25\n",
      "second 770 20\n",
      "first 25 25\n",
      "second 780 0\n",
      "first 25 26\n",
      "second 790 10\n",
      "first 26 26\n",
      "second 800 20\n",
      "first 26 26\n",
      "second 810 0\n",
      "first 26 27\n",
      "second 820 10\n",
      "first 27 27\n",
      "second 830 20\n",
      "first 27 27\n",
      "second 840 0\n",
      "first 27 28\n",
      "second 850 10\n",
      "first 28 28\n",
      "second 860 20\n",
      "first 28 28\n",
      "second 870 0\n",
      "first 28 29\n",
      "second 880 10\n",
      "first 29 29\n",
      "second 890 20\n",
      "first 29 29\n",
      "second 900 0\n",
      "first 29 30\n",
      "second 910 10\n",
      "first 30 30\n",
      "second 920 20\n",
      "first 30 30\n",
      "second 930 0\n",
      "first 30 31\n",
      "second 940 10\n",
      "first 31 31\n",
      "second 950 20\n",
      "first 31 31\n",
      "second 960 0\n",
      "first 31 32\n",
      "second 970 10\n",
      "first 32 32\n",
      "second 980 20\n",
      "first 32 32\n",
      "second 990 0\n",
      "first 32 33\n",
      "second 1000 10\n",
      "first 33 33\n",
      "second 1010 20\n",
      "first 33 33\n",
      "second 1020 0\n",
      "first 33 34\n",
      "second 1030 10\n",
      "first 34 34\n",
      "second 1040 20\n",
      "first 34 34\n",
      "second 1050 0\n",
      "first 34 35\n",
      "second 1060 10\n",
      "first 35 35\n",
      "second 1070 20\n",
      "first 35 35\n",
      "second 1080 0\n",
      "first 35 36\n",
      "second 1090 10\n",
      "first 36 36\n",
      "second 1100 20\n",
      "first 36 36\n",
      "second 1110 0\n",
      "first 36 37\n",
      "second 1120 10\n",
      "first 37 37\n",
      "second 1130 20\n",
      "first 37 37\n",
      "second 1140 0\n",
      "first 37 38\n",
      "second 1150 10\n",
      "first 38 38\n",
      "second 1160 20\n",
      "first 38 38\n",
      "second 1170 0\n",
      "first 38 39\n",
      "second 1180 10\n",
      "first 39 39\n",
      "second 1190 20\n",
      "first 39 39\n",
      "second 1200 0\n",
      "first 39 40\n",
      "second 1210 10\n",
      "first 40 40\n",
      "second 1220 20\n",
      "first 40 40\n",
      "second 1230 0\n",
      "first 40 41\n",
      "second 1240 10\n",
      "first 41 41\n",
      "second 1250 20\n",
      "first 41 41\n",
      "second 1260 0\n",
      "first 41 42\n",
      "second 1270 10\n",
      "first 42 42\n",
      "second 1280 20\n",
      "first 42 42\n",
      "second 1290 0\n",
      "first 42 43\n",
      "second 1300 10\n",
      "first 43 43\n",
      "second 1310 20\n",
      "first 43 43\n",
      "second 1320 0\n",
      "first 43 44\n",
      "second 1330 10\n",
      "first 44 44\n",
      "second 1340 20\n",
      "first 44 44\n",
      "second 1350 0\n",
      "first 44 45\n",
      "second 1360 10\n",
      "first 45 45\n",
      "second 1370 20\n",
      "first 45 45\n",
      "second 1380 0\n",
      "first 45 46\n",
      "second 1390 10\n",
      "first 46 46\n",
      "second 1400 20\n",
      "first 46 46\n",
      "second 1410 0\n",
      "first 46 47\n",
      "second 1420 10\n",
      "first 47 47\n",
      "second 1430 20\n",
      "first 47 47\n",
      "second 1440 0\n",
      "first 47 48\n",
      "second 1450 10\n",
      "first 48 48\n",
      "second 1460 20\n",
      "first 48 48\n",
      "second 1470 0\n",
      "first 48 49\n",
      "second 1480 10\n",
      "first 49 49\n",
      "second 1490 20\n",
      "first 49 49\n",
      "second 1500 0\n"
     ]
    }
   ],
   "source": [
    "test_interval = 30\n",
    "frames_per_batch = 10\n",
    "current_frames = 0\n",
    "for i in range(150):\n",
    "    current_frames += frames_per_batch\n",
    "    prev_test_frame = ((i - 1) * frames_per_batch) // test_interval\n",
    "    cur_test_frame = (i * frames_per_batch) // test_interval\n",
    "\n",
    "    print(\"first\", prev_test_frame, cur_test_frame)\n",
    "    print(\"second\", current_frames, current_frames % test_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=500_100,\n",
    "    init_random_frames=init_rand_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    create_env_fn=env,\n",
    "    policy=policy_explore,\n",
    "    frames_per_batch=10,\n",
    "    total_frames=5_100,\n",
    "    device=\"cpu\",\n",
    "    storing_device=\"cpu\",\n",
    "    max_frames_per_traj=-1,\n",
    "    init_random_frames=10_0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024_07_18-18_37_34'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "date_str = current_date.strftime(\"%Y_%m_%d-%H_%M_%S\")  # Includes date and time\n",
    "date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 17:48:41,856 [torchrl][INFO] solved after 1000 steps, 10 episodes and in 2365.736939430237s.\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "total_episodes = 0\n",
    "t0 = time.time()\n",
    "for i, data in enumerate(collector):\n",
    "    # Write data in replay buffer\n",
    "    rb.extend(data)\n",
    "    max_length = rb[:][\"next\", \"step_count\"].max() # From all the next steps get the max step count\n",
    "    if len(rb) > init_rand_steps: # wam-up steps\n",
    "        # Optim loop (we do several optim steps\n",
    "        # per batch collected for efficiency)\n",
    "        for _ in range(optim_steps):\n",
    "            sample = rb.sample(128) # sample a batch of 128 (repetition is allowed)\n",
    "            loss_vals = loss(sample)\n",
    "            loss_vals[\"loss\"].backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            # Update exploration factor\n",
    "            # NOTE: Why I am updating the exploration factor here? \n",
    "            # I'm considering practically that I did 100 (or n) iteractions in the environment time optim_steps\n",
    "            exploration_module.step(data.numel()) # data.numel() returns the number of elements in the data\n",
    "            # Update target params each optimisation step\n",
    "            updater.step()\n",
    "            if i % 10:\n",
    "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
    "            total_count += data.numel()\n",
    "            total_episodes += data[\"next\", \"done\"].sum() # sum the number of done episodes\n",
    "    if max_length > 200:\n",
    "        break\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "torchrl_logger.info(\n",
    "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_env.rollout(max_steps=1000, policy=policy)\n",
    "video_recorder.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118398, 676190, 786456, 171936, 887739, 919409, 711872, 442081, 189061, 117840]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate and print 10 random seeds\n",
    "random_seeds = [random.randint(0, 1000000) for _ in range(10)]\n",
    "print(random_seeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
